{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VEvRUB3tncrl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils import resample\n",
        "from sklearn import preprocessing\n",
        "from warnings import simplefilter\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "\n",
        "start_time = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frd9aXk9uzEn",
        "outputId": "b8b8db5f-f26a-4052-abca-f666a1148e6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_0tS77BB6vd",
        "outputId": "a70ecb5e-0435-4570-c00d-be0049f7d290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing and undersampling of file Tuesday-WorkingHours.pcap_ISCX is done\n",
            "Preprocessing and undersampling of file Wednesday-workingHours.pcap_ISCX is done\n",
            "Preprocessing and undersampling of file Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX is done\n",
            "Preprocessing and undersampling of file Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX is done\n",
            "Preprocessing and undersampling of file Friday-WorkingHours-Morning.pcap_ISCX is done\n",
            "Preprocessing and undersampling of file Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX is done\n",
            "Preprocessing and undersampling of file Friday-WorkingHours-Afternoon-DDos.pcap_ISCX is done\n",
            "Concatenation and saving to CSV is done\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "processed_dataframes = []\n",
        "\n",
        "std_scaler = StandardScaler()\n",
        "\n",
        "\n",
        "def normalize_dataframe(df, columns_to_normalize):\n",
        "    df[columns_to_normalize] = std_scaler.fit_transform(df[columns_to_normalize])\n",
        "    return df\n",
        "\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/MachineLearningCVE/'\n",
        "\n",
        "\n",
        "all_files = [\n",
        "    \"TWH.pcap_ISCX\",\n",
        "    \"WWH.pcap_ISCX\",\n",
        "    \"TWHMW.pcap_ISCX\",\n",
        "    \"TWHAI.pcap_ISCX\",\n",
        "    \"FWHM.pcap_ISCX\",\n",
        "    \"FWHAP.pcap_ISCX\",\n",
        "    \"FWHAD.pcap_ISCX\"\n",
        "]\n",
        "\n",
        "\n",
        "for file_name in all_files:\n",
        "    file_path = folder_path + file_name + \".csv\"\n",
        "\n",
        "   \n",
        "    try:\n",
        "        df = pd.read_csv(file_path, encoding='iso-8859-2', engine='python')\n",
        "    except UnicodeDecodeError:\n",
        "        df = pd.read_csv(file_path, encoding='utf-8', engine='python')\n",
        "\n",
        "    df = pd.DataFrame(df)\n",
        "\n",
        "   \n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    df = df.drop(df[pd.isnull(df[\"Flow Duration\"])].index)\n",
        "\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    numeric_columns = df.select_dtypes(include='number').columns\n",
        "    df[numeric_columns] = df[numeric_columns].astype(np.float32)\n",
        "    df = normalize_dataframe(df.copy(), numeric_columns)\n",
        "\n",
        "\n",
        "    string_columns = [col for col in df.columns if df[col].dtype == \"object\"]\n",
        "    try:\n",
        "        string_columns.remove('Label')\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "\n",
        "    label_encoder_X = LabelEncoder()\n",
        "    for col in string_columns:\n",
        "        try:\n",
        "            df[col] = label_encoder_X.fit_transform(df[col])\n",
        "        except:\n",
        "            df[col] = df[col].replace('Infinity', -1)\n",
        "\n",
        "    processed_dataframes.append(df)\n",
        "    print(f\"Preprocessing and undersampling of file {file_name} is done\")\n",
        "\n",
        "combined_dataframe = pd.concat(processed_dataframes, ignore_index=True)\n",
        "\n",
        "combined_dataframe.to_csv(\"/content/combined_data.csv\", index=False)\n",
        "print(\"Concatenation and saving to CSV is done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S_9XT3W7o80c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "attack_types = [\"Bot\", \"DDoS\", \"DoS GoldenEye\", \"DoS Hulk\", \"DoS Slowhttptest\", \"DoS slowloris\", \"FTP-Patator\",\n",
        "                \"Heartbleed\", \"Infiltration\", \"PortScan\", \"SSH-Patator\", \"Web Attack - Brute Force\",\n",
        "                \"Web Attack - Sql Injection\", \"Web Attack - XSS\"]\n",
        "benign_type = \"BENIGN\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn6xd8fIqs9b",
        "outputId": "b4ddbb4d-ed35-4e2d-d45c-b2e4981c5ee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved DDoS_vs_BENIGN.csv\n",
            "Saved Infiltration_vs_BENIGN.csv\n",
            "Saved PortScan_vs_BENIGN.csv\n",
            "Saved SSH-Patator_vs_BENIGN.csv\n",
            "Saved Web Attack  Brute Force_vs_BENIGN.csv\n",
            "Saved Web Attack  Sql Injection_vs_BENIGN.csv\n",
            "Saved Web Attack  XSS_vs_BENIGN.csv\n",
            "Execution time: 1826.76 seconds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.utils import resample\n",
        "from sklearn import preprocessing\n",
        "from warnings import simplefilter\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "main_dataset = pd.read_csv(\"combined_data.csv\")\n",
        "\n",
        "\n",
        "attack_types = [\"DDoS\", \"Infiltration\", \"PortScan\", \"SSH-Patator\", \"Web Attack  Brute Force\",\n",
        "                \"Web Attack  Sql Injection\", \"Web Attack  XSS\"]\n",
        "benign_type = \"BENIGN\"\n",
        "\n",
        "for attack_type in attack_types:\n",
        "\n",
        "    attack_data = main_dataset[main_dataset[\"Label\"] == attack_type]\n",
        "\n",
        "\n",
        "    benign_data = main_dataset[main_dataset[\"Label\"] == benign_type]\n",
        "\n",
        "    combined_data = pd.concat([attack_data, benign_data], axis=0)\n",
        "\n",
        "    combined_data = combined_data.sample(frac=1, random_state=42)\n",
        "\n",
        "    output_filename = f\"{attack_type}_vs_{benign_type}.csv\"\n",
        "    combined_data.to_csv(output_filename, index=False)\n",
        "    print(f\"Saved {output_filename}\")\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Execution time: {execution_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEPFEnkyLmtn",
        "outputId": "91fa15e4-d8cb-4605-d292-941bfef68301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moved DDoS_vs_BENIGN.csv to Google Drive.\n",
            "Moved Infiltration_vs_BENIGN.csv to Google Drive.\n",
            "Moved PortScan_vs_BENIGN.csv to Google Drive.\n",
            "Moved SSH-Patator_vs_BENIGN.csv to Google Drive.\n",
            "Moved Web Attack  Brute Force_vs_BENIGN.csv to Google Drive.\n",
            "Moved Web Attack  Sql Injection_vs_BENIGN.csv to Google Drive.\n",
            "Moved Web Attack  XSS_vs_BENIGN.csv to Google Drive.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/MLCVE/'\n",
        "\n",
        "\n",
        "output_files = [\n",
        "    \"DDoS_vs_BENIGN.csv\",\n",
        "    \"Infiltration_vs_BENIGN.csv\",\n",
        "    \"PortScan_vs_BENIGN.csv\",\n",
        "    \"SSH-Patator_vs_BENIGN.csv\",\n",
        "    \"Web Attack  Brute Force_vs_BENIGN.csv\",\n",
        "    \"Web Attack  Sql Injection_vs_BENIGN.csv\",\n",
        "    \"Web Attack  XSS_vs_BENIGN.csv\"\n",
        "]\n",
        "\n",
        "import os\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "\n",
        "for file in output_files:\n",
        "    try:\n",
        "        \n",
        "        if os.path.exists(file):\n",
        "            shutil.move(file, folder_path + file)  # Move the file to Google Drive\n",
        "            print(f\"Moved {file} to Google Drive.\")\n",
        "        else:\n",
        "            print(f\"{file} does not exist locally.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error moving {file}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONYLEN-IiE1c",
        "outputId": "91b2fa0f-debf-4ae8-c13b-40d49f30da60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: DDoS_vs_BENIGN.csv\n",
            "Number of Benign instances: 1741839\n",
            "Number of Attack instances: 128025\n",
            "Shape of the dataset: (1869864, 79)\n",
            "-----------------------------\n",
            "File: Infiltration_vs_BENIGN.csv\n",
            "Number of Benign instances: 1741839\n",
            "Number of Attack instances: 36\n",
            "Shape of the dataset: (1741875, 79)\n",
            "-----------------------------\n",
            "File: PortScan_vs_BENIGN.csv\n",
            "Number of Benign instances: 1741839\n",
            "Number of Attack instances: 158804\n",
            "Shape of the dataset: (1900643, 79)\n",
            "-----------------------------\n",
            "File: SSH-Patator_vs_BENIGN.csv\n",
            "Number of Benign instances: 1741839\n",
            "Number of Attack instances: 5897\n",
            "Shape of the dataset: (1747736, 79)\n",
            "-----------------------------\n",
            "File: Web Attack  Brute Force_vs_BENIGN.csv\n",
            "Number of Benign instances: 1741839\n",
            "Number of Attack instances: 0\n",
            "Shape of the dataset: (1741839, 79)\n",
            "-----------------------------\n",
            "File: Web Attack  Sql Injection_vs_BENIGN.csv\n",
            "Number of Benign instances: 1741839\n",
            "Number of Attack instances: 0\n",
            "Shape of the dataset: (1741839, 79)\n",
            "-----------------------------\n",
            "File: Web Attack  XSS_vs_BENIGN.csv\n",
            "Number of Benign instances: 1741839\n",
            "Number of Attack instances: 0\n",
            "Shape of the dataset: (1741839, 79)\n",
            "-----------------------------\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/MLCVE/'\n",
        "\n",
        "\n",
        "file_names = [\n",
        "    'DDoS_vs_BENIGN.csv',\n",
        "    'Infiltration_vs_BENIGN.csv',\n",
        "    'PortScan_vs_BENIGN.csv',\n",
        "    'SSH-Patator_vs_BENIGN.csv',\n",
        "    'Web Attack  Brute Force_vs_BENIGN.csv',\n",
        "    'Web Attack  Sql Injection_vs_BENIGN.csv',\n",
        "    'Web Attack  XSS_vs_BENIGN.csv'\n",
        "]\n",
        "\n",
        "for file_name in file_names:\n",
        "  \n",
        "    file_path = folder_path + file_name\n",
        "\n",
        " \n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    # Count the number of benign and attack instances\n",
        "    num_benign = (data['Label'] == 'BENIGN').sum()\n",
        "    num_attack = (data['Label'] != 'BENIGN').sum()\n",
        "\n",
        "    print(f\"File: {file_name}\")\n",
        "    print(f\"Number of Benign instances: {num_benign}\")\n",
        "    print(f\"Number of Attack instances: {num_attack}\")\n",
        "    print(\"Shape of the dataset:\", data.shape)\n",
        "    print(\"-----------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gji6jZzlllv1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Folder path where your files are located in Google Drive\n",
        "folder_path = '/content/drive/MyDrive/MLCVE/'\n",
        "\n",
        "\n",
        "attack_types = [\"DDoS\", \"Infiltration\", \"PortScan\", \"SSH-Patator\", \"Web Attack - Brute Force\",\n",
        "                \"Web Attack - Sql Injection\", \"Web Attack - XSS\"]\n",
        "benign_type = \"BENIGN\"\n",
        "\n",
        "\n",
        "def perform_feature_selection(data):\n",
        "    X = data.drop(columns=[\"Label\"])\n",
        "    y = data[\"Label\"].apply(lambda x: 1 if x != benign_type else 0)\n",
        "\n",
        "    clf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    clf.fit(X, y)\n",
        "\n",
        "    importances = clf.feature_importances_\n",
        "    return importances\n",
        "\n",
        "for attack_type in attack_types:\n",
        "\n",
        "    input_filename = f\"{folder_path}{attack_type}_vs_{benign_type}.csv\"\n",
        "\n",
        "    try:\n",
        "    \n",
        "        attack_data = pd.read_csv(input_filename, low_memory=False)\n",
        "\n",
        "\n",
        "        importances = perform_feature_selection(attack_data)\n",
        "\n",
        "\n",
        "        importance_df = pd.DataFrame({\"Feature\": attack_data.drop(columns=[\"Label\"]).columns,\n",
        "                                      \"Importance\": importances})\n",
        "\n",
        " \n",
        "        total_importance = importance_df[\"Importance\"].sum()\n",
        "        importance_df[\"Percentage\"] = importance_df[\"Importance\"] / total_importance * 100\n",
        "\n",
        "\n",
        "        importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "\n",
        "        print(f\"\\nTop 20 features and their percentages for {attack_type}:\")\n",
        "        print(importance_df.head(20))\n",
        "\n",
        "        importance_filename = f\"{folder_path}{attack_type}_importance.csv\"\n",
        "        importance_df.to_csv(importance_filename, index=False)\n",
        "        print(f\"Saved importance list for {attack_type}\")\n",
        "\n",
        "        \n",
        "        plt.figure(figsize=(10, 6))\n",
        "        top_20_df = importance_df.head(20)\n",
        "        top_20_df.plot(kind=\"bar\", x=\"Feature\", y=\"Importance\", legend=None)\n",
        "        plt.title(f\"Feature Importance for {attack_type}\")\n",
        "        plt.xlabel(\"Feature\")\n",
        "        plt.ylabel(\"Importance\")\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File {input_filename} not found. Please check the file path.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing {attack_type}: {e}\")\n",
        "\n",
        "print(\"Feature selection and visualization completed for all attack types.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
